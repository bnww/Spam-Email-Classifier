{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "a = 0.00137714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.587746394105945"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "testing_spam = np.loadtxt(open(\"testing_spam.csv\"), delimiter=\",\")\n",
    "training_spam = np.loadtxt(open(\"training_spam.csv\"), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This skeleton code simply classifies every input as ham\n",
    "#\n",
    "# Here you can see there is a parameter k that is unused, the\n",
    "# point is to show you how you could set up your own. You might\n",
    "# also pass in extra data via a train method (also does nothing\n",
    "#Â here). Modify this code as much as you like so long as the \n",
    "# accuracy test in the cell below runs.\n",
    "\n",
    "class SpamClassifier:\n",
    "    def train(self):\n",
    "        training_labels = training_spam[:,0]\n",
    "        training_features = training_spam[:, 1:]\n",
    "        \n",
    "        # estimating log class priors from the training data\n",
    "        spam_proportion = sum(training_labels) / len(training_labels)\n",
    "        self.log_class_priors = np.array([np.log(1 - spam_proportion), np.log(spam_proportion)])\n",
    "        \n",
    "        # separating the ham from the spam\n",
    "        hams_indices = np.where(training_labels == 0)\n",
    "        hams = training_features[hams_indices] \n",
    "    \n",
    "        spams_indices = np.where(training_labels == 1)\n",
    "        spams = training_features[spams_indices]\n",
    "        \n",
    "        # estimating log class conditional likelihoods\n",
    "        alpha = 1\n",
    "        k = training_features.shape[1] # total number of keywords\n",
    "\n",
    "        spam_featurewise_totals = np.sum(spams, axis = 0) # an array showing the total for each keyword for spam with shape = (1, n_features) \n",
    "        spam_total_features = sum(spam_featurewise_totals) # total number of all features\n",
    "        spam_theta = (spam_featurewise_totals + alpha) / (spam_total_features + (k * alpha)) # relative spam feature frequencies calculated with laplace smoothing\n",
    "\n",
    "        ham_featurewise_totals = np.sum(hams, axis = 0)\n",
    "        ham_total_features = sum(ham_featurewise_totals)\n",
    "        ham_theta = (ham_featurewise_totals + alpha) / (ham_total_features + (k * alpha))\n",
    "        \n",
    "        self.log_class_conditionals = np.array([np.log(ham_theta), np.log(spam_theta)])\n",
    "        \n",
    "    def predict(self, data):\n",
    "        rows, cols = data.shape\n",
    "    \n",
    "        class_predictions = np.zeros(rows)\n",
    "\n",
    "        for i in range(rows):\n",
    "            # initialising log posterior probabilities\n",
    "            ham_email = 0\n",
    "            spam_email = 0\n",
    "            for j in range(cols):\n",
    "                # for each feature, if it is in the email add the respective log probabilities for spam and ham \n",
    "                feature_response = data[i,j]\n",
    "\n",
    "                ham_class_likelihood = self.log_class_conditionals[0,j]\n",
    "                spam_class_likelihood = self.log_class_conditionals[1,j]\n",
    "\n",
    "                ham_email += (feature_response * ham_class_likelihood)\n",
    "                spam_email += (feature_response * spam_class_likelihood)\n",
    "                \n",
    "            # finally add the log_class priors to each, then compare whether spam or ham is more likely\n",
    "            ham_email += self.log_class_priors[0]\n",
    "            spam_email += self.log_class_priors[1]\n",
    "\n",
    "            if spam_email > ham_email: # if spam more likely than ham, classify as 1, otherwise leave as 0 for ham\n",
    "                class_predictions[i] = 1\n",
    "\n",
    "        return class_predictions\n",
    "    \n",
    "\n",
    "def create_classifier():\n",
    "    classifier = SpamClassifier()\n",
    "    classifier.train()\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier:\n",
    "    def __init__(self, alpha = 10):\n",
    "        # separating the ham from the spam\n",
    "        hams_indices = np.where(training_spam[:,0] == 0)\n",
    "        self.hams = training_spam[:,1:][hams_indices] \n",
    "    \n",
    "        spams_indices = np.where(training_spam[:,0] == 1)\n",
    "        self.spams = training_spam[:,1:][spams_indices]\n",
    "        \n",
    "        # for laplace smoothing:\n",
    "        self.alpha = alpha\n",
    "        self.k = training_spam.shape[1] - 1 # number of keyword columns\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        # estimating log class priors from the training data\n",
    "        spam_proportion = self.spams.shape[0] / training_spam.shape[0]\n",
    "        self.log_class_priors = np.array([np.log(1 - spam_proportion), np.log(spam_proportion)])\n",
    "        \n",
    "        # estimating log class conditional likelihoods\n",
    "        spam_featurewise_totals = np.sum(self.spams, axis = 0) # an array showing the total for each keyword for spam with shape = (1, n_features) \n",
    "        spam_total_features = sum(spam_featurewise_totals) # total number of all features\n",
    "        spam_theta = (spam_featurewise_totals + self.alpha) / (spam_total_features + (self.k * self.alpha)) # relative spam feature frequencies calculated with laplace smoothing\n",
    "\n",
    "        ham_featurewise_totals = np.sum(self.hams, axis = 0)\n",
    "        ham_total_features = sum(ham_featurewise_totals)\n",
    "        ham_theta = (ham_featurewise_totals + self.alpha) / (ham_total_features + (self.k * self.alpha))\n",
    "        \n",
    "        self.log_class_conditionals = np.array([np.log(ham_theta), np.log(spam_theta)])\n",
    "        \n",
    "    def predict(self, data):\n",
    "        rows, cols = data.shape\n",
    "        class_predictions = np.zeros(rows)\n",
    "\n",
    "        for i in range(rows):\n",
    "            # initialising log posterior probabilities for both classes\n",
    "            ham_email = 0\n",
    "            spam_email = 0\n",
    "            for j in range(cols):\n",
    "                # for each feature, if it is in the email add the respective log probabilities for spam and ham \n",
    "                feature_response = data[i,j]\n",
    "\n",
    "                ham_class_likelihood = self.log_class_conditionals[0,j]\n",
    "                spam_class_likelihood = self.log_class_conditionals[1,j]\n",
    "\n",
    "                ham_email += (feature_response * ham_class_likelihood)\n",
    "                spam_email += (feature_response * spam_class_likelihood)\n",
    "                \n",
    "            # finally add the log_class priors to each, then compare whether spam or ham is more likely\n",
    "            ham_email += self.log_class_priors[0]\n",
    "            spam_email += self.log_class_priors[1]\n",
    "\n",
    "            if spam_email > ham_email: # if spam more likely than ham, classify as 1, otherwise leave as 0 for ham\n",
    "                class_predictions[i] = 1\n",
    "\n",
    "        return class_predictions\n",
    "    \n",
    "\n",
    "def create_classifier():\n",
    "    classifier = SpamClassifier()\n",
    "    classifier.train()\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.888\n",
      "Accuracy on the testing set: 0.906\n"
     ]
    }
   ],
   "source": [
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "\n",
    "training_predictions = classifier.predict(training_spam[:, 1:])\n",
    "testing_predictions = classifier.predict(testing_spam[:, 1:])\n",
    "\n",
    "# Check data type(s)\n",
    "assert(isinstance(class_predictions, np.ndarray))\n",
    "\n",
    "# Check shape of numpy array\n",
    "assert(class_predictions.shape == (1000,))\n",
    "\n",
    "# Check data type of array elements\n",
    "assert(np.all(np.logical_or(class_predictions == 0, class_predictions == 1)))\n",
    "\n",
    "# Check accuracy\n",
    "\n",
    "training_true_classes = training_spam[:, 0]\n",
    "training_set_accuracy = np.mean(np.equal(training_predictions, training_true_classes))\n",
    "\n",
    "testing_true_classes = testing_spam[:, 0]\n",
    "testing_set_accuracy = np.mean(np.equal(testing_predictions, testing_true_classes))\n",
    "\n",
    "print(f\"Accuracy on the training set: {training_set_accuracy}\")\n",
    "print(f\"Accuracy on the testing set: {testing_set_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-39e353d395ab>:29: RuntimeWarning: divide by zero encountered in log\n",
      "  self.log_class_conditionals = np.array([np.log(ham_theta), np.log(spam_theta)])\n",
      "<ipython-input-78-39e353d395ab>:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  spam_email += (feature_response * spam_class_likelihood)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: {0: 0.602, 1: 0.9, 2: 0.9, 3: 0.898, 4: 0.898, 5: 0.896, 6: 0.894, 7: 0.894, 8: 0.89, 9: 0.892, 10: 0.894, 11: 0.894, 12: 0.894, 13: 0.894, 14: 0.892, 15: 0.892, 16: 0.89, 17: 0.89, 18: 0.89, 19: 0.89, 20: 0.892, 21: 0.892, 22: 0.892, 23: 0.892, 24: 0.892, 25: 0.892, 26: 0.9, 27: 0.9, 28: 0.9, 29: 0.902, 30: 0.9, 31: 0.9, 32: 0.898, 33: 0.898, 34: 0.898, 35: 0.898, 36: 0.898, 37: 0.898, 38: 0.898, 39: 0.898, 40: 0.898, 41: 0.898, 42: 0.898, 43: 0.898, 44: 0.898, 45: 0.898, 46: 0.898, 47: 0.898, 48: 0.896, 49: 0.896, 50: 0.898, 51: 0.898, 52: 0.898, 53: 0.898, 54: 0.896, 55: 0.898, 56: 0.898, 57: 0.898, 58: 0.898, 59: 0.898, 60: 0.898, 61: 0.898, 62: 0.898, 63: 0.898, 64: 0.898, 65: 0.9, 66: 0.9, 67: 0.9, 68: 0.9, 69: 0.9, 70: 0.9, 71: 0.898, 72: 0.898, 73: 0.898, 74: 0.894, 75: 0.894, 76: 0.894, 77: 0.894, 78: 0.894, 79: 0.894, 80: 0.894, 81: 0.894, 82: 0.894, 83: 0.894, 84: 0.894, 85: 0.894, 86: 0.894, 87: 0.894, 88: 0.894, 89: 0.894, 90: 0.894, 91: 0.896, 92: 0.896, 93: 0.896, 94: 0.896, 95: 0.896, 96: 0.896, 97: 0.896, 98: 0.896, 99: 0.896}\n",
      "\n",
      "Accuracy on the testing set: {0: 0.613, 1: 0.885, 2: 0.884, 3: 0.883, 4: 0.882, 5: 0.883, 6: 0.882, 7: 0.882, 8: 0.883, 9: 0.883, 10: 0.881, 11: 0.88, 12: 0.88, 13: 0.878, 14: 0.878, 15: 0.878, 16: 0.879, 17: 0.879, 18: 0.879, 19: 0.88, 20: 0.881, 21: 0.882, 22: 0.881, 23: 0.881, 24: 0.882, 25: 0.882, 26: 0.888, 27: 0.888, 28: 0.889, 29: 0.889, 30: 0.889, 31: 0.889, 32: 0.889, 33: 0.889, 34: 0.889, 35: 0.889, 36: 0.888, 37: 0.888, 38: 0.887, 39: 0.886, 40: 0.886, 41: 0.887, 42: 0.886, 43: 0.886, 44: 0.886, 45: 0.886, 46: 0.886, 47: 0.886, 48: 0.886, 49: 0.886, 50: 0.885, 51: 0.885, 52: 0.885, 53: 0.885, 54: 0.885, 55: 0.885, 56: 0.885, 57: 0.885, 58: 0.885, 59: 0.885, 60: 0.885, 61: 0.885, 62: 0.885, 63: 0.885, 64: 0.885, 65: 0.885, 66: 0.886, 67: 0.886, 68: 0.886, 69: 0.886, 70: 0.887, 71: 0.887, 72: 0.887, 73: 0.887, 74: 0.885, 75: 0.885, 76: 0.885, 77: 0.885, 78: 0.885, 79: 0.885, 80: 0.885, 81: 0.886, 82: 0.886, 83: 0.886, 84: 0.886, 85: 0.886, 86: 0.885, 87: 0.885, 88: 0.885, 89: 0.89, 90: 0.89, 91: 0.89, 92: 0.89, 93: 0.892, 94: 0.892, 95: 0.893, 96: 0.894, 97: 0.895, 98: 0.895, 99: 0.896}\n",
      "\n",
      "Max alpha, accurary for training: 29, 0.902\n",
      "Max alpha, accurary for testing: 99, 0.896\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = {}\n",
    "testing_accuracy = {}\n",
    "\n",
    "for i in range(100):\n",
    "    classifier = SpamClassifier(alpha = i)\n",
    "    classifier.train()\n",
    "    training_predictions = classifier.predict(training_spam[:, 1:])\n",
    "    testing_predictions = classifier.predict(testing_spam[:, 1:])\n",
    "\n",
    "    training_true_classes = training_spam[:, 0]\n",
    "    training_set_accuracy = np.mean(np.equal(training_predictions, training_true_classes))\n",
    "\n",
    "    testing_true_classes = testing_spam[:, 0]\n",
    "    testing_set_accuracy = np.mean(np.equal(testing_predictions, testing_true_classes))\n",
    "    \n",
    "    training_accuracy[i] = training_set_accuracy\n",
    "    testing_accuracy[i] = testing_set_accuracy\n",
    "\n",
    "print(f\"Accuracy on the training set: {training_accuracy}\\n\")\n",
    "print(f\"Accuracy on the testing set: {testing_accuracy}\")\n",
    "\n",
    "score_training = max(training_accuracy.values())\n",
    "score_testing = max(testing_accuracy.values())\n",
    "\n",
    "alpha_training = max(training_accuracy, key = training_accuracy.get)\n",
    "alpha_testing = max(testing_accuracy, key = testing_accuracy.get)\n",
    "\n",
    "print(f\"\\nMax alpha, accurary for training: {alpha_training}, {score_training}\")\n",
    "print(f\"Max alpha, accurary for testing: {alpha_testing}, {score_testing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam training: 0.9457364341085271\n",
      "Ham training: 0.8515497553017944\n",
      "\n",
      "Spam testing: 0.9346733668341709\n",
      "Ham testing: 0.8870431893687708\n"
     ]
    }
   ],
   "source": [
    "train_hams_indices = np.where(training_spam[:,0] == 0)\n",
    "train_hams = training_spam[:,1:][train_hams_indices]\n",
    "    \n",
    "train_spams_indices = np.where(training_spam[:,0] == 1)\n",
    "train_spams = training_spam[:,1:][train_spams_indices]\n",
    "\n",
    "test_hams_indices = np.where(testing_spam[:,0] == 0)\n",
    "test_hams = testing_spam[:,1:][test_hams_indices] \n",
    "    \n",
    "test_spams_indices = np.where(testing_spam[:,0] == 1)\n",
    "test_spams = testing_spam[:,1:][test_spams_indices]\n",
    "\n",
    "ham_training_predictions = classifier.predict(train_hams)\n",
    "spam_training_predictions = classifier.predict(train_spams)\n",
    "\n",
    "ham_testing_predictions = classifier.predict(test_hams)\n",
    "spam_testing_predictions = classifier.predict(test_spams)\n",
    "\n",
    "ham_class = 0\n",
    "spam_class = 1\n",
    "\n",
    "hams_training_accuracy = np.mean(np.equal(ham_training_predictions, 0))\n",
    "spams_training_accuracy = np.mean(np.equal(spam_training_predictions, 1))\n",
    "\n",
    "hams_testing_accuracy = np.mean(np.equal(ham_testing_predictions, 0))\n",
    "spams_testing_accuracy = np.mean(np.equal(spam_testing_predictions, 1))\n",
    "\n",
    "print(f\"Spam training: {spams_training_accuracy}\")\n",
    "print(f\"Ham training: {hams_training_accuracy}\")\n",
    "\n",
    "print(f\"\\nSpam testing: {spams_testing_accuracy}\")\n",
    "print(f\"Ham testing: {hams_testing_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
