{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "a = 0.00137714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.587746394105945"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_spam = np.loadtxt(open(\"training_spam.csv\"), delimiter=\",\")\n",
    "testing_spam = np.loadtxt(open(\"testing_spam.csv\"), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This skeleton code simply classifies every input as ham\n",
    "#\n",
    "# Here you can see there is a parameter k that is unused, the\n",
    "# point is to show you how you could set up your own. You might\n",
    "# also pass in extra data via a train method (also does nothing\n",
    "#Â here). Modify this code as much as you like so long as the \n",
    "# accuracy test in the cell below runs.\n",
    "\n",
    "class SpamClassifier:\n",
    "    def train(self):\n",
    "        training_labels = training_spam[:,0]\n",
    "        training_features = training_spam[:, 1:]\n",
    "        \n",
    "        # estimating log class priors from the training data\n",
    "        spam_proportion = sum(training_labels) / len(training_labels)\n",
    "        self.log_class_priors = np.array([np.log(1 - spam_proportion), np.log(spam_proportion)])\n",
    "        \n",
    "        # separating the ham from the spam\n",
    "        hams_indices = np.where(training_labels == 0)\n",
    "        hams = training_features[hams_indices] \n",
    "    \n",
    "        spams_indices = np.where(training_labels == 1)\n",
    "        spams = training_features[spams_indices]\n",
    "        \n",
    "        # estimating log class conditional likelihoods\n",
    "        alpha = 1\n",
    "        k = training_features.shape[1] # total number of keywords\n",
    "\n",
    "        spam_featurewise_totals = np.sum(spams, axis = 0) # an array showing the total for each keyword for spam with shape = (1, n_features) \n",
    "        spam_total_features = sum(spam_featurewise_totals) # total number of all features\n",
    "        spam_theta = (spam_featurewise_totals + alpha) / (spam_total_features + (k * alpha)) # relative spam feature frequencies calculated with laplace smoothing\n",
    "\n",
    "        ham_featurewise_totals = np.sum(hams, axis = 0)\n",
    "        ham_total_features = sum(ham_featurewise_totals)\n",
    "        ham_theta = (ham_featurewise_totals + alpha) / (ham_total_features + (k * alpha))\n",
    "        \n",
    "        self.log_class_conditionals = np.array([np.log(ham_theta), np.log(spam_theta)])\n",
    "        \n",
    "    def predict(self, data):\n",
    "        rows, cols = data.shape\n",
    "    \n",
    "        class_predictions = np.zeros(rows)\n",
    "\n",
    "        for i in range(rows):\n",
    "            # initialising log posterior probabilities\n",
    "            ham_email = 0\n",
    "            spam_email = 0\n",
    "            for j in range(cols):\n",
    "                # for each feature, if it is in the email add the respective log probabilities for spam and ham \n",
    "                feature_response = data[i,j]\n",
    "\n",
    "                ham_class_likelihood = self.log_class_conditionals[0,j]\n",
    "                spam_class_likelihood = self.log_class_conditionals[1,j]\n",
    "\n",
    "                ham_email += (feature_response * ham_class_likelihood)\n",
    "                spam_email += (feature_response * spam_class_likelihood)\n",
    "                \n",
    "            # finally add the log_class priors to each, then compare whether spam or ham is more likely\n",
    "            ham_email += self.log_class_priors[0]\n",
    "            spam_email += self.log_class_priors[1]\n",
    "\n",
    "            if spam_email > ham_email: # if spam more likely than ham, classify as 1, otherwise leave as 0 for ham\n",
    "                class_predictions[i] = 1\n",
    "\n",
    "        return class_predictions\n",
    "    \n",
    "\n",
    "def create_classifier():\n",
    "    classifier = SpamClassifier()\n",
    "    classifier.train()\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier:\n",
    "    def __init__(self, alpha = 1):\n",
    "        # separating the ham from the spam\n",
    "        hams_indices = np.where(training_spam[:,0] == 0)\n",
    "        self.hams = training_spam[:,1:][hams_indices] \n",
    "    \n",
    "        spams_indices = np.where(training_spam[:,0] == 1)\n",
    "        self.spams = training_spam[:,1:][spams_indices]\n",
    "        \n",
    "        # for laplace smoothing:\n",
    "        self.alpha = alpha\n",
    "        self.k = training_spam.shape[1] - 1 # number of keyword columns\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        # estimating log class priors from the training data\n",
    "        spam_proportion = self.spams.shape[0] / training_spam.shape[0]\n",
    "        self.log_class_priors = np.array([np.log(1 - spam_proportion), np.log(spam_proportion)])\n",
    "        \n",
    "        # estimating log class conditional likelihoods\n",
    "        spam_featurewise_totals = np.sum(self.spams, axis = 0) # an array showing the total for each keyword for spam with shape = (1, n_features) \n",
    "        spam_total_features = sum(spam_featurewise_totals) # total number of all features\n",
    "        spam_theta = (spam_featurewise_totals + self.alpha) / (spam_total_features + (self.k * self.alpha)) # relative spam feature frequencies calculated with laplace smoothing\n",
    "\n",
    "        ham_featurewise_totals = np.sum(self.hams, axis = 0)\n",
    "        ham_total_features = sum(ham_featurewise_totals)\n",
    "        ham_theta = (ham_featurewise_totals + self.alpha) / (ham_total_features + (self.k * self.alpha))\n",
    "        \n",
    "        self.log_class_conditionals = np.array([np.log(ham_theta), np.log(spam_theta)])\n",
    "        \n",
    "    def predict(self, data):\n",
    "        rows, cols = data.shape\n",
    "        class_predictions = np.zeros(rows)\n",
    "\n",
    "        for i in range(rows):\n",
    "            # initialising log posterior probabilities for both classes\n",
    "            ham_email = 0\n",
    "            spam_email = 0\n",
    "            for j in range(cols):\n",
    "                # for each feature, if it is in the email add the respective log probabilities for spam and ham \n",
    "                feature_response = data[i,j]\n",
    "\n",
    "                ham_class_likelihood = self.log_class_conditionals[0,j]\n",
    "                spam_class_likelihood = self.log_class_conditionals[1,j]\n",
    "\n",
    "                ham_email += (feature_response * ham_class_likelihood)\n",
    "                spam_email += (feature_response * spam_class_likelihood)\n",
    "                \n",
    "            # finally add the log_class priors to each, then compare whether spam or ham is more likely\n",
    "            ham_email += self.log_class_priors[0]\n",
    "            spam_email += self.log_class_priors[1]\n",
    "\n",
    "            if spam_email > ham_email: # if spam more likely than ham, classify as 1, otherwise leave as 0 for ham\n",
    "                class_predictions[i] = 1\n",
    "\n",
    "        return class_predictions\n",
    "    \n",
    "\n",
    "def create_classifier():\n",
    "    classifier = SpamClassifier()\n",
    "    classifier.train()\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.892\n",
      "Accuracy on the testing set: 0.898\n"
     ]
    }
   ],
   "source": [
    "# You can use this cell to check whether the returned objects of your function are of the right data type.\n",
    "\n",
    "training_predictions = classifier.predict(training_spam[:, 1:])\n",
    "testing_predictions = classifier.predict(testing_spam[:, 1:])\n",
    "\n",
    "# Check data type(s)\n",
    "assert(isinstance(class_predictions, np.ndarray))\n",
    "\n",
    "# Check shape of numpy array\n",
    "assert(class_predictions.shape == (1000,))\n",
    "\n",
    "# Check data type of array elements\n",
    "assert(np.all(np.logical_or(class_predictions == 0, class_predictions == 1)))\n",
    "\n",
    "# Check accuracy\n",
    "\n",
    "training_true_classes = training_spam[:, 0]\n",
    "training_set_accuracy = np.mean(np.equal(training_predictions, training_true_classes))\n",
    "\n",
    "testing_true_classes = testing_spam[:, 0]\n",
    "testing_set_accuracy = np.mean(np.equal(testing_predictions, testing_true_classes))\n",
    "\n",
    "print(f\"Accuracy on the training set: {training_set_accuracy}\")\n",
    "print(f\"Accuracy on the testing set: {testing_set_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-39e353d395ab>:29: RuntimeWarning: divide by zero encountered in log\n",
      "  self.log_class_conditionals = np.array([np.log(ham_theta), np.log(spam_theta)])\n",
      "<ipython-input-52-39e353d395ab>:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  spam_email += (feature_response * spam_class_likelihood)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: {0: 0.613, 1: 0.892, 2: 0.893, 3: 0.891, 4: 0.889, 5: 0.889, 6: 0.889, 7: 0.887, 8: 0.888, 9: 0.888, 10: 0.888, 11: 0.888, 12: 0.888, 13: 0.888, 14: 0.888, 15: 0.887, 16: 0.888, 17: 0.888, 18: 0.888, 19: 0.887, 20: 0.887, 21: 0.89, 22: 0.89, 23: 0.89, 24: 0.89, 25: 0.89, 26: 0.889, 27: 0.889, 28: 0.888, 29: 0.888, 30: 0.888, 31: 0.888, 32: 0.889, 33: 0.888, 34: 0.888, 35: 0.889, 36: 0.889, 37: 0.889, 38: 0.889, 39: 0.894, 40: 0.894, 41: 0.894, 42: 0.894, 43: 0.896, 44: 0.896, 45: 0.896, 46: 0.896, 47: 0.895, 48: 0.896, 49: 0.897, 50: 0.896, 51: 0.896, 52: 0.896, 53: 0.895, 54: 0.894, 55: 0.894, 56: 0.894, 57: 0.894, 58: 0.894, 59: 0.892, 60: 0.892, 61: 0.893, 62: 0.893, 63: 0.893, 64: 0.893, 65: 0.894, 66: 0.894, 67: 0.894, 68: 0.894, 69: 0.894, 70: 0.894, 71: 0.894, 72: 0.895, 73: 0.895, 74: 0.895, 75: 0.893, 76: 0.893, 77: 0.897, 78: 0.897, 79: 0.897, 80: 0.897, 81: 0.896, 82: 0.896, 83: 0.896, 84: 0.896, 85: 0.896, 86: 0.896, 87: 0.896, 88: 0.896, 89: 0.896, 90: 0.896, 91: 0.896, 92: 0.897, 93: 0.897, 94: 0.897, 95: 0.896, 96: 0.896, 97: 0.896, 98: 0.896, 99: 0.896}\n",
      "\n",
      "Accuracy on the testing set: {0: 0.602, 1: 0.898, 2: 0.904, 3: 0.902, 4: 0.902, 5: 0.902, 6: 0.902, 7: 0.902, 8: 0.904, 9: 0.904, 10: 0.906, 11: 0.906, 12: 0.906, 13: 0.904, 14: 0.904, 15: 0.904, 16: 0.906, 17: 0.906, 18: 0.906, 19: 0.902, 20: 0.902, 21: 0.9, 22: 0.9, 23: 0.9, 24: 0.902, 25: 0.902, 26: 0.902, 27: 0.902, 28: 0.9, 29: 0.9, 30: 0.9, 31: 0.9, 32: 0.9, 33: 0.9, 34: 0.9, 35: 0.898, 36: 0.898, 37: 0.898, 38: 0.896, 39: 0.906, 40: 0.906, 41: 0.904, 42: 0.904, 43: 0.904, 44: 0.904, 45: 0.904, 46: 0.906, 47: 0.906, 48: 0.906, 49: 0.906, 50: 0.906, 51: 0.906, 52: 0.906, 53: 0.906, 54: 0.906, 55: 0.904, 56: 0.904, 57: 0.904, 58: 0.904, 59: 0.904, 60: 0.904, 61: 0.902, 62: 0.902, 63: 0.902, 64: 0.902, 65: 0.902, 66: 0.902, 67: 0.902, 68: 0.902, 69: 0.902, 70: 0.902, 71: 0.902, 72: 0.902, 73: 0.902, 74: 0.902, 75: 0.898, 76: 0.898, 77: 0.898, 78: 0.898, 79: 0.898, 80: 0.898, 81: 0.898, 82: 0.898, 83: 0.898, 84: 0.898, 85: 0.898, 86: 0.898, 87: 0.898, 88: 0.898, 89: 0.898, 90: 0.898, 91: 0.898, 92: 0.898, 93: 0.898, 94: 0.898, 95: 0.898, 96: 0.898, 97: 0.898, 98: 0.898, 99: 0.898}\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = {}\n",
    "testing_accuracy = {}\n",
    "\n",
    "for i in range(100):\n",
    "    classifier = SpamClassifier(alpha = i) \n",
    "    classifier.train()\n",
    "    training_predictions = classifier.predict(training_spam[:, 1:])\n",
    "    testing_predictions = classifier.predict(testing_spam[:, 1:])\n",
    "\n",
    "    training_true_classes = training_spam[:, 0]\n",
    "    training_set_accuracy = np.mean(np.equal(training_predictions, training_true_classes))\n",
    "\n",
    "    testing_true_classes = testing_spam[:, 0]\n",
    "    testing_set_accuracy = np.mean(np.equal(testing_predictions, testing_true_classes))\n",
    "    \n",
    "    training_accuracy[i] = training_set_accuracy\n",
    "    testing_accuracy[i] = testing_set_accuracy\n",
    "\n",
    "print(f\"Accuracy on the training set: {training_accuracy}\\n\")\n",
    "print(f\"Accuracy on the testing set: {testing_accuracy}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
